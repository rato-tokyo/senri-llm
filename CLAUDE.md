# Senri-LLM Development Guidelines

## Project Overview

Senri-LLMã¯ã€**SmolLM-135M**ã‚’ãƒ™ãƒ¼ã‚¹ã«ã€Infini Attentionã‚’å®Ÿè£…ã™ã‚‹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã™ã€‚

**ç¾åœ¨ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹**: ã‚·ãƒ³ãƒ—ãƒ«åŒ–ãƒ•ã‚§ãƒ¼ã‚ºï¼ˆå˜ä¸€ãƒ†ãƒ³ã‚½ãƒ«ç©ãƒ¡ãƒ¢ãƒªã§åŸºæœ¬å‹•ä½œã‚’ç¢ºèªä¸­ï¼‰

## Small Model Philosophy - é‡è¦

### ãªãœå°å‹ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã™ã‚‹ã®ã‹

Senriã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¯ã€**ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·ã«é–¢ä¿‚ãªãå›ºå®šã‚µã‚¤ã‚ºã®ãƒ¡ãƒ¢ãƒª**ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚

```python
# ãƒ¡ãƒ¢ãƒªã‚µã‚¤ã‚ºã¯å›ºå®šï¼ˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·ã«ä¾å­˜ã—ãªã„ï¼‰
M = torch.zeros(batch, heads, head_dim, head_dim)  # å­¦ç¿’ãƒ»æ¨è«–å…±é€š
```

ã“ã‚Œã«ã‚ˆã‚Šã€**ãŸã¨ãˆ16M tokensã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§ã‚ã£ã¦ã‚‚**ã€æœ€çµ‚çš„ã«ã¯ï¼š
- ãƒ†ãƒ³ã‚½ãƒ«ç©ãƒ¡ãƒ¢ãƒªï¼ˆå›ºå®šã‚µã‚¤ã‚ºï¼‰
- SWAã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ï¼ˆå›ºå®šã‚µã‚¤ã‚ºï¼‰

ã«åã¾ã‚‹ãŸã‚ã€**ç†è«–ä¸Šã¯å°å‹ãƒ¢ãƒ‡ãƒ«ã§ã‚‚è¶…é•·æ–‡ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å‡¦ç†å¯èƒ½**ã§ã™ã€‚

### è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ vs ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆè¨˜æ†¶

| è¦³ç‚¹ | å¤§å‹ãƒ¢ãƒ‡ãƒ« | å°å‹ãƒ¢ãƒ‡ãƒ« |
|------|-----------|-----------|
| è¤‡é›‘ãªæ¨è«– | å¾—æ„ | é™å®šçš„ |
| ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆè¨˜æ†¶ | å¾—æ„ | **Senriã§å¯¾å¿œå¯èƒ½** |
| å­¦ç¿’ã‚³ã‚¹ãƒˆ | é«˜ã„ | ä½ã„ |
| å®Ÿé¨“é€Ÿåº¦ | é…ã„ | é€Ÿã„ |

**é‡è¦**: ã€Œé•·æ–‡ã‚’è¨˜æ†¶ã§ãã‚‹ã‹ã€ã¨ã€Œè¤‡é›‘ãªæ¨è«–ãŒã§ãã‚‹ã‹ã€ã¯åˆ¥ã®èƒ½åŠ›ã§ã™ã€‚
Senriã®ç›®æ¨™ã¯**ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆè¨˜æ†¶èƒ½åŠ›ã®è¨¼æ˜**ã§ã‚ã‚Šã€è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã¯å¯¾è±¡å¤–ã§ã™ã€‚

### å°å‹ãƒ¢ãƒ‡ãƒ«ã§ã®é•·æ–‡è¨˜æ†¶å®Ÿè¨¼ã®æ„ç¾©

1. **åŠ¹ç‡çš„ãªå®Ÿé¨“**: Colab T4ã§ååˆ†ãªå­¦ç¿’ãƒ»è©•ä¾¡ãŒå¯èƒ½
2. **ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®æ¤œè¨¼**: ãƒ¡ãƒ¢ãƒªæ©Ÿæ§‹ãŒæ­£ã—ãå‹•ä½œã™ã‚‹ã“ã¨ã‚’è¨¼æ˜
3. **ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã®ç¤ºå”†**: å°å‹ã§å‹•ã‘ã°å¤§å‹ã§ã‚‚å‹•ã

### å­¦ç¿’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·ã®é‡è¦æ€§

```
ãƒ¡ãƒ¢ãƒªã‚’æ´»ç”¨ã™ã‚‹å­¦ç¿’ã®ãŸã‚ã«ã¯:
  å­¦ç¿’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•· > SWAã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚º

ç¾åœ¨ã®è¨­å®š:
  max_length: 2048 tokens (å­¦ç¿’)
  sliding_window_size: 1024 tokens (SWA)
  â†’ ãƒ¡ãƒ¢ãƒªãŒç©æ¥µçš„ã«ä½¿ç”¨ã•ã‚Œã‚‹
```

## Training Data Strategy - é‡è¦

### ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: PG19ï¼ˆé•·ç·¨æ›¸ç±ï¼‰

HSAè«–æ–‡ã®çŸ¥è¦‹ã«åŸºã¥ãã€**å®ŸåŠ¹ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·ãŒé•·ã„ãƒ‡ãƒ¼ã‚¿**ã‚’ä½¿ç”¨ã™ã‚‹ã€‚

| é …ç›® | WikiText-2 | PG19 |
|------|-----------|------|
| å¹³å‡é•· | æ•°ç™¾ãƒˆãƒ¼ã‚¯ãƒ³ | æ•°ä¸‡ãƒˆãƒ¼ã‚¯ãƒ³ |
| é•·è·é›¢ä¾å­˜ | ã»ã¼ãªã— | ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è¿½è·¡ã€ä¼ç·š |
| ç”¨é€” | çŸ­æ–‡ãƒ†ã‚¹ãƒˆ | **é•·æ–‡ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå­¦ç¿’** |

### NIAHï¼ˆNeedle-in-a-Haystackï¼‰ã‚¿ã‚¹ã‚¯æ··å…¥

HSAè«–æ–‡ Section 3.2:
> "Synthetic ruler tasks are randomly inserted into **1% of training samples**"

```yaml
# config/training.yaml
dataset:
  name: "pg19"
  niah_ratio: 0.01  # 1%ã®NIAHã‚¿ã‚¹ã‚¯æ··å…¥
```

NIAHã‚¿ã‚¹ã‚¯ã®å½¢å¼:
```
[é•·ã„æ–‡ç« ...]
The secret key is: KEY-ABC12345
[ã•ã‚‰ã«é•·ã„æ–‡ç« ...]

Question: What is the secret key mentioned above?
Answer: KEY-ABC12345
```

### HSAè«–æ–‡ã‹ã‚‰ã®å­¦ã³

1. **å®ŸåŠ¹ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·ãŒæ±åŒ–ã«æ±ºå®šçš„**
   - å˜ã«é•·ã„ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã§ã¯ãªãã€å‰åŠã‚’å‚ç…§ã—ãªã„ã¨å¾ŒåŠãŒç†è§£ã§ããªã„æ§‹é€ ãŒå¿…è¦
   - å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®å®ŸåŠ¹é•· > 32K ã§å¤–æŒ¿æ€§èƒ½ãŒå¤§å¹…æ”¹å–„

2. **SWA/ãƒ¡ãƒ¢ãƒªã®ã‚·ãƒ¼ã‚½ãƒ¼åŠ¹æœ**
   - å¤§ãã™ãã‚‹SWAçª“ â†’ ãƒ¡ãƒ¢ãƒªã®å­¦ç¿’ãŒé˜»å®³ã•ã‚Œã‚‹
   - ç¾åœ¨ã®è¨­å®šï¼ˆSWA=1024, å­¦ç¿’é•·=2048ï¼‰ã¯é©åˆ‡

3. **Warm-upã¯äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã§ã¯ä¸è¦**
   - HSAã®Warm-upã¯ã‚¼ãƒ­ã‹ã‚‰ã®å­¦ç¿’ç”¨
   - SmolLMã¯æ—¢ã«å­¦ç¿’æ¸ˆã¿ãªã®ã§ã€ç›´æ¥é•·æ–‡ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’å¯èƒ½

## Architecture Specification

### Core Conceptï¼ˆç¾åœ¨: ã‚·ãƒ³ãƒ—ãƒ«åŒ–ç‰ˆï¼‰

```
å­¦ç¿’æ™‚ãƒ»æ¨è«–æ™‚: åŒã˜å˜ä¸€ãƒ†ãƒ³ã‚½ãƒ«ç©ãƒ¡ãƒ¢ãƒªï¼ˆæ¨™æº–Infini Attentionï¼‰

å°†æ¥: ç›´äº¤åŸºåº•ãƒ™ãƒ¼ã‚¹ã®å‹•çš„ãƒ†ãƒ³ã‚½ãƒ«ç©é¸æŠï¼ˆæ¨è«–æ™‚ã®ã¿ï¼‰
```

**ã‚·ãƒ³ãƒ—ãƒ«åŒ–ã®ç†ç”±**: ã¾ãšåŸºæœ¬çš„ãªInfini AttentionãŒæ­£ã—ãå‹•ä½œã™ã‚‹ã“ã¨ã‚’ç¢ºèªã™ã‚‹

### Base Model: SmolLM-135M

| é …ç›® | å€¤ |
|------|-----|
| ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•° | 135M |
| hidden_size | 576 |
| num_layers | 30 |
| num_attention_heads | 9 |
| num_key_value_heads | 3 (GQA) |
| head_dim | 64 |
| vocab_size | 49,152 |

### Layer Structure (30 layers total)

```
Layer 0-9:   SWA only (Lower Decoder)
Layer 10:    SWA + Senri Memory (Group 1)
Layer 11-19: SWA only
Layer 20:    SWA + Senri Memory (Group 2)
Layer 21-29: SWA only
```

### Memory Layer Configuration

- `num_memory_layers`: 2 (Senri Memoryã‚’æŒã¤ãƒ¬ã‚¤ãƒ¤ãƒ¼æ•°)
- `first_memory_layer`: 10 (æœ€åˆã®ãƒ¡ãƒ¢ãƒªãƒ¬ã‚¤ãƒ¤ãƒ¼)
- `memory_layer_interval`: 10 (ãƒ¡ãƒ¢ãƒªãƒ¬ã‚¤ãƒ¤ãƒ¼é–“éš”)
- ãƒ¡ãƒ¢ãƒªãƒ¬ã‚¤ãƒ¤ãƒ¼ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: [10, 20]

### Memory Sharing Policy

**ç¾çŠ¶: å„å±¤ãŒç‹¬ç«‹ã—ãŸãƒ¡ãƒ¢ãƒªã‚’æŒã¤ï¼ˆIndependent Memoryï¼‰**

```
Layer 12: SenriMemory_1 (ç‹¬ç«‹)
Layer 16: SenriMemory_2 (ç‹¬ç«‹)
Layer 20: SenriMemory_3 (ç‹¬ç«‹)
```

- å„å±¤ãŒç‹¬è‡ªã® `SenriMemory` ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä¿æŒ
- å±¤é–“ã§ãƒ¡ãƒ¢ãƒªçŠ¶æ…‹ã¯å…±æœ‰ã•ã‚Œãªã„
- ãƒ¡ãƒªãƒƒãƒˆ: å„å±¤ãŒç•°ãªã‚‹æŠ½è±¡åº¦ã®æƒ…å ±ã‚’ä¿æŒå¯èƒ½

**å°†æ¥æ¤œè¨: å˜ä¸€å…±æœ‰ãƒ¡ãƒ¢ãƒªï¼ˆShared Memoryï¼‰**

Infini-Attentionè«–æ–‡ã§ã¯å˜ä¸€ãƒ¡ãƒ¢ãƒªã‚’è¤‡æ•°å±¤ã§å…±æœ‰ã™ã‚‹ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚‚è­°è«–ã•ã‚Œã¦ã„ã‚‹ã€‚
æœ€å¤§ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦é”æˆã®ãŸã‚ã€å°†æ¥çš„ã«å…±æœ‰ãƒ¡ãƒ¢ãƒªæ–¹å¼ã‚‚æ¤œè¨äºˆå®šã€‚

```
Layer 12, 16, 20: SharedSenriMemory (å…±æœ‰)
```

### Positional Encoding

- **SWA (Local Attention)**: RoPEä½¿ç”¨
- **Senri Memory (Global Attention)**: NoPE (No Positional Encoding)

## è«–æ–‡æº–æ‹ ã®å®Ÿè£…çŠ¶æ³ - é‡è¦

**2024-12-19æ›´æ–°**: è«–æ–‡å®Œå…¨æº–æ‹ ã®å®Ÿè£…ã‚’å®Œäº†ã—ã¾ã—ãŸã€‚

### å®Ÿè£…çŠ¶æ³ä¸€è¦§

| é …ç›® | è«–æ–‡ | ç¾åœ¨ã®å®Ÿè£… | çŠ¶æ…‹ |
|------|------|----------|------|
| æ´»æ€§åŒ–é–¢æ•°Ïƒ | ELU + 1 | `elu_plus_one()` | âœ… å®Ÿè£…æ¸ˆã¿ |
| æ›´æ–°é †åº | retrieve â†’ update | ã‚»ã‚°ãƒ¡ãƒ³ãƒˆå˜ä½ã§é †åºç¶­æŒ | âœ… å®Ÿè£…æ¸ˆã¿ |
| æ­£è¦åŒ–åˆ†æ¯ | clamp(min=eps) | `denominator.clamp(min=eps)` | âœ… å®Ÿè£…æ¸ˆã¿ |
| ã‚»ã‚°ãƒ¡ãƒ³ãƒˆå‡¦ç† | ãƒãƒ£ãƒ³ã‚¯å˜ä½ã§å‡¦ç† | forãƒ«ãƒ¼ãƒ—ã§ã‚»ã‚°ãƒ¡ãƒ³ãƒˆå‡¦ç† | âœ… å®Ÿè£…æ¸ˆã¿ |
| ä½ç½®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚° | ãƒ¡ãƒ¢ãƒª:NoPE, ãƒ­ãƒ¼ã‚«ãƒ«:RoPE | åˆ†é›¢å®Ÿè£… | âœ… å®Ÿè£…æ¸ˆã¿ |
| Deltaæ›´æ–° | ã‚ã‚Šï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰ | Linearæ›´æ–°ã®ã¿ | ğŸ“ å°†æ¥å¯¾å¿œ |

### 1. æ´»æ€§åŒ–é–¢æ•°Ïƒï¼ˆå®Ÿè£…æ¸ˆã¿ï¼‰

**è«–æ–‡**: `Ïƒ(K) = ELU(K) + 1` ã‚’ Keys/Queries ã«é©ç”¨

```python
# base_memory.py
def elu_plus_one(x):
    return F.elu(x) + 1

# updateæ™‚: Ïƒ(K)ã‚’ä½¿ç”¨
sigma_keys = elu_plus_one(keys)
delta_M = torch.einsum("bhsd,bhse->bhde", values, sigma_keys)

# retrieveæ™‚: Ïƒ(Q)ã‚’ä½¿ç”¨
sigma_queries = elu_plus_one(queries)
```

**åŠ¹æœ**: å…¨ã¦ã®å€¤ãŒæ­£ã«ãªã‚Šã€æ­£è¦åŒ–ã®åˆ†æ¯ãŒå¸¸ã«æ­£ï¼ˆNaNé˜²æ­¢ï¼‰

### 2. ã‚»ã‚°ãƒ¡ãƒ³ãƒˆå˜ä½å‡¦ç†ï¼ˆå®Ÿè£…æ¸ˆã¿ï¼‰

**è«–æ–‡** (Section 4.1):
> "we forward-pass the entire input text a Transformer model and then perform segment chunking at each Infini-attention layer"

```python
# senri_attention.py - è«–æ–‡æº–æ‹ ã®å®Ÿè£…
for seg_idx in range(num_segments):
    start = seg_idx * segment_size
    end = min(start + segment_size, seq_len)

    # Step 1: Retrieve from M_{s-1} (éå»ã®ãƒ¡ãƒ¢ãƒª)
    global_output = self.memory.retrieve(seg_query)

    # Step 2: Local attention (A_dot)
    local_output = self._local_attention(seg_query_local, ...)

    # Step 3: Combine with gate
    output = gate * global_output + (1 - gate) * local_output

    # Step 4: Update memory to M_s
    self.memory.update(seg_key, seg_value)
```

**å› æœæ€§ã®ç¶­æŒ**:
- ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ`s`ã®å‡¦ç†æ™‚ã€`M_{s-1}`ï¼ˆéå»ã®ãƒ¡ãƒ¢ãƒªï¼‰ã‹ã‚‰æ¤œç´¢
- ãã®å¾Œã€ç¾åœ¨ã®K,Vã§`M_s`ã«æ›´æ–°
- ã“ã‚Œã«ã‚ˆã‚Šè«–æ–‡ã®`retrieve â†’ update`é †åºãŒå³å¯†ã«å®ˆã‚‰ã‚Œã‚‹

### 3. ä½ç½®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®åˆ†é›¢ï¼ˆå®Ÿè£…æ¸ˆã¿ï¼‰

**è«–æ–‡** (Section 4.1):
> "we don't use position embeddings for the key and query vectors of the compressive memory"

```python
# ãƒ¡ãƒ¢ãƒªæ“ä½œ: NoPEï¼ˆç”Ÿã®Q, K, Vï¼‰
seg_query = query_states[:, :, start:end, :]  # RoPEé©ç”¨å‰
seg_key = key_expanded[:, :, start:end, :]

# ãƒ­ãƒ¼ã‚«ãƒ«Attention: RoPE
seg_query_local = query_local[:, :, start:end, :]  # RoPEé©ç”¨å¾Œ
seg_key_local = key_local[:, :, start:end, :]
```

### 4. Deltaæ›´æ–°ï¼ˆå°†æ¥å¯¾å¿œï¼‰

**è«–æ–‡ã®Deltaæ›´æ–°**:
```python
# æ—¢å­˜ãƒã‚¤ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã‚’å¼•ã„ã¦ã‹ã‚‰æ›´æ–°
retrieved = sigma_K @ M / (sigma_K @ z)
M = M + sigma_K.T @ (V - retrieved)
```

**ç¾åœ¨**: Linearæ›´æ–°ã®ã¿
```python
M = M + K.T @ V
```

**å½±éŸ¿**: åŒã˜ã‚­ãƒ¼ã§ç¹°ã‚Šè¿”ã—æ›´æ–°ã™ã‚‹ã¨å€¤ãŒè“„ç©
**å¦¥å”ã®ç†ç”±**: è«–æ–‡ã§ã‚‚Linearæ›´æ–°ã§è‰¯ã„çµæœã‚’ç¤ºã—ã¦ã„ã‚‹ï¼ˆTable 2ï¼‰

### å®Ÿè£…å®Œäº†ï¼ˆ2024-12-19ï¼‰

**è«–æ–‡å®Œå…¨æº–æ‹ ã®å®Ÿè£…ãŒå®Œäº†ã—ã¾ã—ãŸ:**

1. âœ… ELU+1æ´»æ€§åŒ–é–¢æ•°ï¼ˆÏƒï¼‰
2. âœ… ã‚»ã‚°ãƒ¡ãƒ³ãƒˆå˜ä½å‡¦ç†ï¼ˆãƒãƒ£ãƒ³ã‚¯ãƒ«ãƒ¼ãƒ—ï¼‰
3. âœ… retrieve â†’ update é †åºï¼ˆå› æœæ€§ç¶­æŒï¼‰
4. âœ… clamp(min=eps)ã«ã‚ˆã‚‹å®‰å®šåŒ–
5. âœ… NoPE/RoPEã®åˆ†é›¢

### å°†æ¥å¯¾å¿œ

- ğŸ“ Deltaæ›´æ–°ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³å®Ÿè£…
- ğŸ“ 32Kä»¥ä¸Šã®é•·æ–‡å­¦ç¿’
- ğŸ“ ã‚»ã‚°ãƒ¡ãƒ³ãƒˆé–“BPTTï¼ˆç¾åœ¨ã¯ã‚µãƒ³ãƒ—ãƒ«å†…å‹¾é…ã®ã¿ï¼‰

### ãƒ¡ãƒ¢ãƒªå‹¾é…ã«ã¤ã„ã¦ã®è¨­è¨ˆåˆ¤æ–­

**è«–æ–‡ã®ä»•æ§˜ï¼ˆBPTTï¼‰**:
> "Each Infini-attention layer is trained with back-propagation through time (BPTT) by computing the gradient w.r.t the compressive memory states"

**ç¾åœ¨ã®å®Ÿè£…**:
```python
# base_memory.py - ç´¯ç©çŠ¶æ…‹ã®ã¿detachã€ç¾åœ¨ã®æ›´æ–°ã¯å‹¾é…ã‚’ç¶­æŒ
self.M = self.M.detach() + delta_M  # delta_Mã«ã¯å‹¾é…ã‚ã‚Š
self.z = self.z.detach() + delta_z
```

**å‹¾é…ãƒ•ãƒ­ãƒ¼**:
- ã‚»ã‚°ãƒ¡ãƒ³ãƒˆå†…: âœ… å‹¾é…ãŒæµã‚Œã‚‹ï¼ˆupdate â†’ retrieveçµŒè·¯ï¼‰
- ã‚»ã‚°ãƒ¡ãƒ³ãƒˆé–“: âŒ detachã«ã‚ˆã‚Šåˆ‡æ–­ï¼ˆãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ã‚’é˜²æ­¢ï¼‰

è«–æ–‡ã®å®Œå…¨BPTTã¯ã‚»ã‚°ãƒ¡ãƒ³ãƒˆé–“ã§ã‚‚å‹¾é…ã‚’æµã™ãŒã€ã“ã‚Œã¯ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒå¢—å¤§ã™ã‚‹ã€‚
ç¾åœ¨ã®è¨­è¨ˆã¯ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã¨å­¦ç¿’åŠ¹ç‡ã®ãƒãƒ©ãƒ³ã‚¹ã‚’å–ã£ã¦ã„ã‚‹ã€‚

### æœŸå¾…ã•ã‚Œã‚‹å‹•ä½œ

- **åŸºæœ¬å‹•ä½œ**: âœ… è«–æ–‡æº–æ‹ ã®å®Ÿè£…
- **ãƒ¡ãƒ¢ãƒªã®åŠ¹æœ**: âœ… ã‚»ã‚°ãƒ¡ãƒ³ãƒˆé–“ã§ãƒ¡ãƒ¢ãƒªãŒè“„ç©
- **NIAHã‚¿ã‚¹ã‚¯**: âœ… é•·è·é›¢ä¾å­˜ã‚’å­¦ç¿’å¯èƒ½

**æ ¹æ‹ **:
- è«–æ–‡ã®Linearæ›´æ–°ï¼ˆDeltaæ›´æ–°ãªã—ï¼‰ã§ã‚‚è‰¯å¥½ãªçµæœ
- ã‚»ã‚°ãƒ¡ãƒ³ãƒˆå‡¦ç†ã«ã‚ˆã‚Šå› æœæ€§ãŒç¶­æŒã•ã‚Œã‚‹

## new-llmãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¨ã®æ¯”è¼ƒ - å‚è€ƒæƒ…å ±

åŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«å­˜åœ¨ã™ã‚‹`new-llm`ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚‚åŒæ§˜ã®Infini Attentionå®Ÿè£…ã‚’æŒã¤ã€‚
2024-12-19ã®NaNå•é¡Œè§£æ±ºæ™‚ã«æ¯”è¼ƒåˆ†æã‚’è¡Œã„ã€è¤‡æ•°ã®ä¿®æ­£ã«åæ˜ ã—ãŸã€‚

### new-llmã®æ¦‚è¦

**å ´æ‰€**: `/Users/sakajiritomoyoshi/Desktop/git/new-llm`

**ä¸»è¦ãƒ•ã‚¡ã‚¤ãƒ«**:
- `src/models/memory/base.py` - CompressiveMemoryï¼ˆãƒ¡ãƒ¢ãƒªå®Ÿè£…ï¼‰
- `src/models/layers/senri.py` - SenriAttentionï¼ˆã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³å±¤ï¼‰
- `src/models/memory_utils.py` - ELU+1ç­‰ã®ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£

### senri-llmã¨new-llmã®ä¸»è¦ãªé•ã„

| é …ç›® | senri-llm | new-llm | å‚™è€ƒ |
|------|-----------|---------|------|
| **ãƒ¡ãƒ¢ãƒªå½¢çŠ¶** | `[batch, heads, d, d]` | `[d, d]`ï¼ˆãƒãƒƒãƒå…±æœ‰ï¼‰ | senri-llmã¯ãƒãƒƒãƒç‹¬ç«‹ |
| **ãƒ¡ãƒ¢ãƒªå‹¾é…** | `M.detach() + delta_M` | å®Œå…¨detach | senri-llmã¯ã‚µãƒ³ãƒ—ãƒ«å†…å‹¾é…ç¶­æŒ |
| **æ­£è¦åŒ–ã‚¹ã‚±ãƒ¼ãƒ«** | ãªã— | `/ (batch * seq)` | new-llmã¯å€¤ã‚’æ­£è¦åŒ– |
| **Delta Rule** | æœªå®Ÿè£… | å®Ÿè£…æ¸ˆã¿ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰ | æ€§èƒ½å‘ä¸Šã‚ªãƒ—ã‚·ãƒ§ãƒ³ |
| **è¤‡æ•°ãƒ¡ãƒ¢ãƒª** | å˜ä¸€ãƒ¡ãƒ¢ãƒª | è¤‡æ•°ãƒ¡ãƒ¢ãƒªå¯¾å¿œ | new-llmã¯ç™ºå±•çš„æ©Ÿèƒ½ã‚ã‚Š |
| **freeze/unfreeze** | ãªã— | å®Ÿè£…æ¸ˆã¿ | çŸ¥è­˜ä¿å­˜æ©Ÿèƒ½ |

### new-llmã‹ã‚‰å­¦ã‚“ã ä¿®æ­£ç‚¹ï¼ˆ2024-12-19é©ç”¨ï¼‰

1. **`clamp(min=eps)`ã®ä½¿ç”¨**
   - å…ƒ: `denominator + eps`
   - ä¿®æ­£å¾Œ: `denominator.clamp(min=eps)`
   - ç†ç”±: è² ã®å€¤ã«å¯¾ã—ã¦ã‚‚ãƒ­ãƒã‚¹ãƒˆ

2. **`retrieve â†’ update`é †åº**
   - å…ƒ: `update â†’ retrieve`
   - ä¿®æ­£å¾Œ: `retrieve â†’ update`
   - ç†ç”±: è«–æ–‡æº–æ‹ ã®å› æœæ€§ç¶­æŒã€new-llmã‚‚åŒé †åº

3. **ç©ºãƒ¡ãƒ¢ãƒªãƒã‚§ãƒƒã‚¯**
   - è¿½åŠ : `if z.abs().sum() < eps: return zeros`
   - ç†ç”±: new-llmã®å®‰å…¨æ©Ÿæ§‹ã‚’æ¡ç”¨

### ãªãœnew-llmã§ãƒ¡ãƒ¢ãƒªå‹¾é…ãªã—ã§ã‚‚å‹•ä½œã™ã‚‹ã‹

**ãƒ¡ãƒ¢ãƒªä»¥å¤–ã®å­¦ç¿’å¯èƒ½ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**:
1. **QKVæŠ•å½±** (`nn.Linear`): å…¥åŠ›â†’ãƒ¡ãƒ¢ãƒªã®å¤‰æ›ã‚’å­¦ç¿’
2. **ãƒ¡ãƒ¢ãƒªã‚²ãƒ¼ãƒˆ**: ãƒ¡ãƒ¢ãƒªã®ä½¿ç”¨åº¦åˆã„ã‚’å­¦ç¿’
3. **å‡ºåŠ›æŠ•å½±**: æœ€çµ‚å‡ºåŠ›ã®èª¿æ•´ã‚’å­¦ç¿’

ã“ã‚Œã‚‰ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒå­¦ç¿’ã•ã‚Œã‚‹ãŸã‚ã€ãƒ¡ãƒ¢ãƒªè‡ªä½“ã«å‹¾é…ãŒæµã‚Œãªãã¦ã‚‚ï¼š
- ã€Œã©ã®ã‚ˆã†ãªK,Vã‚’ãƒ¡ãƒ¢ãƒªã«æ ¼ç´ã™ã‚‹ã‹ã€ã¯å­¦ç¿’ã•ã‚Œã‚‹
- ã€Œãƒ¡ãƒ¢ãƒªå‡ºåŠ›ã‚’ã©ã†ä½¿ã†ã‹ã€ã¯å­¦ç¿’ã•ã‚Œã‚‹

**senri-llmã®å„ªä½æ€§**: ã‚µãƒ³ãƒ—ãƒ«å†…å‹¾é…ã‚’ç¶­æŒã™ã‚‹ã“ã¨ã§ã€ãƒ¡ãƒ¢ãƒªã®ä½¿ã„æ–¹ã‚‚ç›´æ¥å­¦ç¿’ã§ãã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚

### æ³¨æ„äº‹é …

- new-llmãŒã€Œæ­£ã—ã„å®Ÿè£…ã€ã¨ã¯é™ã‚‰ãªã„
- ä¸¡ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯ç‹¬è‡ªã®è¨­è¨ˆåˆ¤æ–­ã‚’æŒã¤
- è«–æ–‡ã®BPTTä»•æ§˜ã¯ã©ã¡ã‚‰ã‚‚å®Œå…¨ã«ã¯å®Ÿè£…ã—ã¦ã„ãªã„
- æ¯”è¼ƒã¯å‚è€ƒæƒ…å ±ã¨ã—ã¦ã€ç‹¬è‡ªã®æ¤œè¨¼ãŒå¿…è¦

## Training vs Inference Modeï¼ˆç¾åœ¨: ã‚·ãƒ³ãƒ—ãƒ«åŒ–ç‰ˆï¼‰

**ç¾åœ¨ã®ã‚·ãƒ³ãƒ—ãƒ«åŒ–ç‰ˆã§ã¯ã€å­¦ç¿’ãƒ»æ¨è«–ã§åŒã˜ãƒ¡ãƒ¢ãƒªã‚’ä½¿ç”¨ã€‚**

### æ¯”è¼ƒè¡¨ï¼ˆã‚·ãƒ³ãƒ—ãƒ«åŒ–ç‰ˆï¼‰

| é …ç›® | å­¦ç¿’æ™‚ (`model.train()`) | æ¨è«–æ™‚ (`model.eval()`) |
|------|-------------------------|------------------------|
| **ãƒ¡ãƒ¢ãƒªæ§‹é€ ** | å˜ä¸€ãƒ†ãƒ³ã‚½ãƒ«ç©ãƒ¡ãƒ¢ãƒª (`TensorMemory`) | åŒã˜ |
| **ãƒ¡ãƒ¢ãƒªå½¢çŠ¶** | `[batch, heads, head_dim, head_dim]` | åŒã˜ |
| **ãƒ¡ãƒ¢ãƒªæ›´æ–°** | å˜ç´”ç´¯ç©: `M = M + v âŠ— k` | åŒã˜ |
| **å‹¾é…è¨ˆç®—** | ã‚ã‚Š | ãªã— (`torch.no_grad()`) |
| **ãƒ¡ãƒ¢ãƒªãƒªã‚»ãƒƒãƒˆ** | æ¯ã‚µãƒ³ãƒ—ãƒ«ï¼ˆè‡ªå‹•ï¼‰ | å„ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é–‹å§‹å‰ï¼ˆæ‰‹å‹•ï¼‰ |

### ãƒ¢ãƒ¼ãƒ‰åˆ‡ã‚Šæ›¿ãˆã®æ³¨æ„ç‚¹

```python
# å­¦ç¿’æ™‚: è‡ªå‹•çš„ã«æ¯ã‚µãƒ³ãƒ—ãƒ«ã§ãƒ¡ãƒ¢ãƒªãƒªã‚»ãƒƒãƒˆ
model.train()

# æ¨è«–æ™‚: å„ã‚·ãƒ¼ã‚±ãƒ³ã‚¹å‰ã«æ‰‹å‹•ã§ãƒªã‚»ãƒƒãƒˆ
model.eval()
model.reset_memory(batch_size, device, dtype)
outputs = model.generate(**inputs)
```

### ãƒ¡ãƒ¢ãƒªãƒªã‚»ãƒƒãƒˆã®ã‚¿ã‚¤ãƒŸãƒ³ã‚° - é‡è¦

**âš ï¸ 2024å¹´12æœˆã«ç™ºè¦‹ã—ãŸé‡å¤§ãªãƒã‚°ã¨ãã®ä¿®æ­£**

#### å•é¡Œ

æ¯å›ã®`forward()`ã§ãƒ¡ãƒ¢ãƒªã‚’ãƒªã‚»ãƒƒãƒˆã™ã‚‹ã¨ã€é•·æ–‡æ¨è«–ã§ãƒ¡ãƒ¢ãƒªãŒæ©Ÿèƒ½ã—ãªã„ã€‚

```python
# âŒ é–“é•ã„: æ¯å›ãƒªã‚»ãƒƒãƒˆ
def forward(self, ...):
    self.memory.reset(batch_size, device, dtype)  # éå»ã®æƒ…å ±ãŒæ¶ˆãˆã‚‹ï¼
```

#### æ­£ã—ã„å®Ÿè£…

```python
# âœ… æ­£ã—ã„: æ¡ä»¶ä»˜ããƒªã‚»ãƒƒãƒˆ
def forward(self, ...):
    M = self.memory.memory.M  # TensorMemoryã®M
    needs_reset = (
        M is None
        or self.training  # å­¦ç¿’æ™‚ã¯æ¯å›ãƒªã‚»ãƒƒãƒˆï¼ˆã‚µãƒ³ãƒ—ãƒ«ç‹¬ç«‹ï¼‰
        or M.shape[0] != batch_size  # ãƒãƒƒãƒã‚µã‚¤ã‚ºå¤‰æ›´æ™‚
    )
    if needs_reset:
        self.memory.reset(batch_size, device, dtype)
```

#### ãƒªã‚»ãƒƒãƒˆã‚¿ã‚¤ãƒŸãƒ³ã‚°ã®åŸå‰‡

| ã‚·ãƒŠãƒªã‚ª | ãƒªã‚»ãƒƒãƒˆã‚¿ã‚¤ãƒŸãƒ³ã‚° | ç†ç”± |
|---------|-------------------|------|
| **å­¦ç¿’** | æ¯ã‚µãƒ³ãƒ—ãƒ« | å„ã‚µãƒ³ãƒ—ãƒ«ã¯ç‹¬ç«‹ã€å‹¾é…ã®åˆ†é›¢ |
| **æ¨è«–ï¼ˆçŸ­æ–‡ï¼‰** | æ¯ã‚µãƒ³ãƒ—ãƒ« | ç‹¬ç«‹ã—ãŸè³ªå•ã¸ã®å›ç­” |
| **æ¨è«–ï¼ˆé•·æ–‡ï¼‰** | ã‚·ãƒ¼ã‚±ãƒ³ã‚¹å…ˆé ­ã®ã¿ | ãƒ¡ãƒ¢ãƒªã«éå»æƒ…å ±ã‚’è“„ç© |
| **è©•ä¾¡ï¼ˆNIAHç­‰ï¼‰** | å„ãƒ†ã‚¹ãƒˆå‰ | ãƒ†ã‚¹ãƒˆé–“ã®å¹²æ¸‰ã‚’é˜²æ­¢ |

#### è©•ä¾¡ã‚³ãƒ¼ãƒ‰ã§ã®æ­£ã—ã„ä½¿ç”¨

```python
# NIAHè©•ä¾¡ãªã©ã€å„ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹å‰ã«ãƒªã‚»ãƒƒãƒˆ
if hasattr(model, "reset_memory"):
    model.reset_memory(batch_size, device, dtype)

# ãã®å¾Œgenerate()ã‚’å‘¼ã¶
outputs = model.generate(**inputs)
```

#### æ•™è¨“

1. **ãƒ¡ãƒ¢ãƒªãƒªã‚»ãƒƒãƒˆã¯å‘¼ã³å‡ºã—å´ã®è²¬ä»»**: æ¨è«–æ™‚ã¯`forward()`å†…ã§è‡ªå‹•ãƒªã‚»ãƒƒãƒˆã—ãªã„
2. **è©•ä¾¡ã‚³ãƒ¼ãƒ‰ã¯æ˜ç¤ºçš„ã«ãƒªã‚»ãƒƒãƒˆ**: å„ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹å‰ã«`reset_memory()`ã‚’å‘¼ã¶
3. **å­¦ç¿’æ™‚ã¯æ¯å›ãƒªã‚»ãƒƒãƒˆ**: å„ã‚µãƒ³ãƒ—ãƒ«ã®ç‹¬ç«‹æ€§ã‚’ä¿è¨¼

## Implementation Details

### Tensor Memoryï¼ˆå˜ä¸€ãƒ¡ãƒ¢ãƒªã€å­¦ç¿’ãƒ»æ¨è«–å…±é€šï¼‰

```python
# ãƒ¡ãƒ¢ãƒªæ§‹é€ 
M = torch.zeros(batch, heads, head_dim, head_dim)  # ãƒ†ãƒ³ã‚½ãƒ«ç©
z = torch.zeros(batch, heads, head_dim)            # æ­£è¦åŒ–ä¿‚æ•°

# æ›´æ–°: M = Î£ v âŠ— k
M = M + torch.einsum('bhsd,bhse->bhde', v, k)  # å¤–ç©ã®ç´¯ç©
z = z + k.sum(dim=seq)  # æ­£è¦åŒ–ç”¨

# æ¤œç´¢: output = (M @ q) / (z^T @ q + eps)
numerator = torch.einsum('bhde,bhse->bhsd', M, q)
denominator = torch.einsum('bhd,bhsd->bhs', z, q) + eps
output = numerator / denominator.unsqueeze(-1)
```

**ãƒ†ãƒ³ã‚½ãƒ«ç©ã®æ„å‘³**:
- `v âŠ— k` ã¯ value ã¨ key ã®å¤–ç©
- key ã‚’ query ã¨ã—ã¦æ¤œç´¢ã™ã‚‹ã¨ã€å¯¾å¿œã™ã‚‹ value ãŒè¿”ã‚‹
- è¤‡æ•°ã® KV ãƒšã‚¢ã‚’ç´¯ç©ã™ã‚‹ã“ã¨ã§ã€é€£æƒ³ãƒ¡ãƒ¢ãƒªã¨ã—ã¦æ©Ÿèƒ½

### SVD-based Memory Cleaning (Noise Removal)

ãƒ†ãƒ³ã‚½ãƒ«ç©ãƒ¡ãƒ¢ãƒªã«è“„ç©ã•ã‚Œã‚‹ãƒã‚¤ã‚ºã‚’é™¤å»ã™ã‚‹ãŸã‚ã€å‘¨æœŸçš„SVDã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°æ©Ÿèƒ½ã‚’å®Ÿè£…ã€‚

**åŸç†**: SVDã«ã‚ˆã‚‹ä½ãƒ©ãƒ³ã‚¯è¿‘ä¼¼ï¼ˆEckart-Youngå®šç†ã«åŸºã¥ãæœ€é©è¿‘ä¼¼ï¼‰

```python
# åŸºæœ¬çš„ãªä½¿ç”¨æ–¹æ³•
from src.memory import SenriMemory, SVDCleaningStats

memory = SenriMemory(num_heads=14, head_dim=64, hidden_size=896)
memory.reset(batch_size=1, device=device, dtype=dtype)

# ãƒ¡ãƒ¢ãƒªæ›´æ–°å¾Œã€ãƒã‚¤ã‚ºé™¤å»ã‚’å®Ÿè¡Œ
stats = memory.svd_cleaning(
    energy_threshold=0.95,  # 95%ã®ã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚’ä¿æŒ
    max_rank=None,          # Noneã®å ´åˆã€energy_thresholdã§æ±ºå®š
)

print(f"Original rank: {stats.original_rank}")
print(f"Retained rank: {stats.retained_rank}")
print(f"Energy retained: {stats.energy_retained:.2%}")
```

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**:

| ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ | å‹ | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ | èª¬æ˜ |
|-----------|-----|----------|------|
| `energy_threshold` | float | 0.95 | ä¿æŒã™ã‚‹ã‚¨ãƒãƒ«ã‚®ãƒ¼ã®å‰²åˆï¼ˆç‰¹ç•°å€¤ã®äºŒä¹—å’Œï¼‰ |
| `max_rank` | int | None | æ˜ç¤ºçš„ãªãƒ©ãƒ³ã‚¯ä¸Šé™ã€‚Noneã®å ´åˆã¯energy_thresholdã§æ±ºå®š |

**å®Ÿè¡Œã‚¿ã‚¤ãƒŸãƒ³ã‚°ï¼ˆæœªå®šã€å°†æ¥å®Ÿè£…äºˆå®šï¼‰**:
- ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›å¾…æ©Ÿä¸­ï¼ˆã‚¢ã‚¤ãƒ‰ãƒ«æ™‚ï¼‰
- ä¸€å®šã®ãƒ¡ãƒ¢ãƒªæ›´æ–°å›æ•°ã”ã¨
- ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒé–¾å€¤ã‚’è¶…ãˆãŸæ™‚

**çµ±è¨ˆæƒ…å ±ã®æ´»ç”¨**:

```python
# è©³ç´°ãªçµ±è¨ˆã‚’å–å¾—
stats = memory.svd_cleaning(energy_threshold=0.90)

# ç‰¹ç•°å€¤ã®åˆ†å¸ƒã‚’ç¢ºèªï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
print(f"Top singular values: {stats.singular_values_before[0, :5]}")

```

**æ³¨æ„äº‹é …**:
- SVDè¨ˆç®—ã¯ O(nÂ³) ã®è¨ˆç®—é‡ã€‚é »ç¹ãªå®Ÿè¡Œã¯é¿ã‘ã‚‹
- `torch.no_grad()` å†…ã§å®Ÿè¡Œã•ã‚Œã‚‹ãŸã‚ã€å‹¾é…ã¯è¨ˆç®—ã•ã‚Œãªã„
- ãƒ¡ãƒ¢ãƒªåˆæœŸåŒ–å‰ã«å‘¼ã³å‡ºã™ã¨ `RuntimeError` ãŒç™ºç”Ÿ

### HuggingFace Compatibility

- `SenriConfig`: `LlamaConfig`ã‚’ç¶™æ‰¿ï¼ˆSmolLM, Llamaãƒ•ã‚¡ãƒŸãƒªãƒ¼ã¨äº’æ›ï¼‰
- `SenriForCausalLM`: Llamaã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®æ§‹é€ ã‚’è¸è¥²
- `from_pretrained`/`save_pretrained`å®Œå…¨å¯¾å¿œ
- `generate()`ãƒ¡ã‚½ãƒƒãƒ‰ã§ã®æ¨è«–å¯¾å¿œ

### Key Classes

```python
# src/configuration_senri.py
class SenriConfig(LlamaConfig):
    model_type = "senri"

    # Senri specific
    sliding_window_size: int = 1024
    chunk_size: int = 64
    num_memory_layers: int = 2
    first_memory_layer: int = 10
    memory_layer_interval: int = 10

# src/memory/base_memory.py
class TensorMemory:
    """å˜ä¸€ãƒ†ãƒ³ã‚½ãƒ«ç©ãƒ¡ãƒ¢ãƒªï¼ˆå­¦ç¿’ãƒ»æ¨è«–å…±é€šï¼‰"""

# src/memory/senri_memory.py
class SenriMemory:
    """TensorMemoryã®ãƒ©ãƒƒãƒ‘ãƒ¼ï¼ˆå°†æ¥ã®æ‹¡å¼µç”¨ï¼‰"""

# src/attention/senri_attention.py
class SenriAttention(nn.Module):
    """SWA + Senri Memory Attentionï¼ˆå˜ä¸€ãƒ¡ãƒ¢ãƒªç‰ˆï¼‰"""
```

## Configuration Management Policy

### è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ™ãƒ¼ã‚¹ã®ç®¡ç†ï¼ˆé‡è¦ï¼‰

**å…¨ã¦ã®å®Ÿé¨“ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ `config/` ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®YAMLãƒ•ã‚¡ã‚¤ãƒ«ã§ç®¡ç†ã™ã‚‹ã€‚**

ã‚¹ã‚¯ãƒªãƒ—ãƒˆã«ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã¯ç¦æ­¢ã€‚è¨­å®šå¤‰æ›´ã¯å¿…ãšconfigãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç·¨é›†ã—ã¦è¡Œã†ã€‚

### Config Directory Structure

```
config/
â”œâ”€â”€ model.yaml       # ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­å®š
â”œâ”€â”€ training.yaml    # å­¦ç¿’ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
â””â”€â”€ experiment.yaml  # å®Ÿé¨“å…¨ä½“ã®è¨­å®š
```

### è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®å½¹å‰²

| ãƒ•ã‚¡ã‚¤ãƒ« | å†…å®¹ |
|---------|------|
| `model.yaml` | vocab_size, hidden_size, num_layers, memory layerè¨­å®šãªã© |
| `training.yaml` | epochs, batch_size, learning_rate, optimizerè¨­å®šãªã© |
| `experiment.yaml` | output_dir, benchmarkè¨­å®š, Colabè¨­å®šãªã© |

### ä½¿ç”¨æ–¹æ³•

```python
from src.config import ConfigManager

# å…¨è¨­å®šã‚’èª­ã¿è¾¼ã¿
config = ConfigManager()

# å€‹åˆ¥ã‚¢ã‚¯ã‚»ã‚¹
model_name = config.base_model_name
batch_size = config.batch_size

# TrainingConfigã«å¤‰æ›
training_config = config.to_training_config()

# SenriConfigã«å¤‰æ›
senri_config = config.to_senri_config()
```

### ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œ

```bash
# å¼•æ•°ãªã—ã§å®Ÿè¡Œï¼ˆconfig/*.yamlã‹ã‚‰è¨­å®šã‚’èª­ã¿è¾¼ã‚€ï¼‰
python scripts/colab.py train
python scripts/colab.py test
python scripts/colab.py eval
```

### ç¦æ­¢äº‹é …

- â›” ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¸ã®argparseå¼•æ•°è¿½åŠ 
- â›” ã‚³ãƒ¼ãƒ‰å†…ã§ã®ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
- â›” ç’°å¢ƒå¤‰æ•°ã«ã‚ˆã‚‹è¨­å®šï¼ˆç‰¹æ®Šãªå ´åˆã‚’é™¤ãï¼‰

### è¨­å®šå¤‰æ›´ã®æ‰‹é †

1. `config/*.yaml` ã‚’ç·¨é›†
2. å¤‰æ›´ã‚’ã‚³ãƒŸãƒƒãƒˆ
3. ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œ

## Coding Standards

### File Naming
- ã‚¹ãƒãƒ¼ã‚¯ã‚±ãƒ¼ã‚¹: `tensor_memory.py`, `senri_attention.py`
- ã‚¯ãƒ©ã‚¹å: ãƒ‘ã‚¹ã‚«ãƒ«ã‚±ãƒ¼ã‚¹ `SenriAttention`, `TensorMemory`

### Import Order
1. æ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
2. ã‚µãƒ¼ãƒ‰ãƒ‘ãƒ¼ãƒ†ã‚£ (torch, transformers)
3. ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

### Type Hints
- å…¨ã¦ã®é–¢æ•°ã«å‹ãƒ’ãƒ³ãƒˆã‚’ä»˜ä¸
- Tensorã®å½¢çŠ¶ã¯docstringã§ã‚³ãƒ¡ãƒ³ãƒˆ

```python
def forward(
    self,
    hidden_states: torch.Tensor,  # [batch, seq, hidden]
    attention_mask: Optional[torch.Tensor] = None,
) -> torch.Tensor:
    """
    Args:
        hidden_states: [batch_size, seq_len, hidden_size]
        attention_mask: [batch_size, 1, seq_len, seq_len]

    Returns:
        output: [batch_size, seq_len, hidden_size]
    """
```

## Testing Requirements

### Unit Tests
- å„ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã«å¯¾å¿œã™ã‚‹ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«
- `pytest`ä½¿ç”¨

### Test Cases
1. `TensorMemory`: æ›´æ–°ã¨æ¤œç´¢ã®æ­£ç¢ºæ€§
2. `SenriAttention`: ãƒ¡ãƒ¢ãƒªãƒªã‚»ãƒƒãƒˆã®å‹•ä½œ
3. `SenriForCausalLM`: SmolLMé‡ã¿ã®ãƒ­ãƒ¼ãƒ‰

### Shape Tests
```python
def test_tensor_memory_shapes():
    memory = TensorMemory(hidden_size=576, num_heads=9)
    q = torch.randn(2, 9, 100, 64)
    k = torch.randn(2, 9, 100, 64)
    v = torch.randn(2, 9, 100, 64)

    memory.update(k, v)
    output = memory.retrieve(q)

    assert output.shape == (2, 9, 100, 64)
```

## Git Workflow

### Branch Strategy
- `main`: å®‰å®šç‰ˆ
- `dev`: é–‹ç™ºç‰ˆ
- `feature/*`: æ©Ÿèƒ½é–‹ç™º

### Commit Message Format
```
<type>: <subject>

<body>

<footer>
```

Types: `feat`, `fix`, `docs`, `refactor`, `test`, `chore`

## Performance Considerations

### Memory Efficiency
- æ¨è«–æ™‚ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’æœ€å°åŒ–
- ä¸è¦ãªãƒ†ãƒ³ã‚½ãƒ«ã®å³åº§è§£æ”¾
- `torch.no_grad()`ã®é©åˆ‡ãªä½¿ç”¨

### Computational Efficiency
- ãƒ†ãƒ³ã‚½ãƒ«ç©ãƒ¡ãƒ¢ãƒªã¯ O(dÂ²) ã®ãƒ¡ãƒ¢ãƒªã§ä»»æ„é•·ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’å‡¦ç†å¯èƒ½
- SWAã¯ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºå†…ã®ã¿è¨ˆç®—ã™ã‚‹ãŸã‚ O(nãƒ»w) ã®è¨ˆç®—é‡

## Dependencies

```
torch>=2.0.0
transformers>=4.36.0
accelerate>=0.25.0
datasets>=2.14.0
```

## Common Pitfalls

### 1. ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯
```python
# Bad
self.memory_history.append(memory.clone())

# Good
self.memory_history.append(memory.detach().clone())
```

### 2. å­¦ç¿’/æ¨è«–ãƒ¢ãƒ¼ãƒ‰æ··åŒ
```python
# ãƒ¢ãƒ¼ãƒ‰ã«ã‚ˆã‚‹ãƒ¡ãƒ¢ãƒªãƒªã‚»ãƒƒãƒˆã®é•ã„ã«æ³¨æ„
if self.training:
    # æ¯ã‚µãƒ³ãƒ—ãƒ«è‡ªå‹•ãƒªã‚»ãƒƒãƒˆ
else:
    # æ‰‹å‹•ãƒªã‚»ãƒƒãƒˆãŒå¿…è¦
```

### 3. ä½ç½®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®æ··åœ¨
```python
# SWA: RoPEé©ç”¨
# Senri Memory: RoPEé©ç”¨ã—ãªã„ï¼ˆNoPEï¼‰
```

### 4. ãƒ¡ãƒ¢ãƒªã®æ¯å›ãƒªã‚»ãƒƒãƒˆï¼ˆè‡´å‘½çš„ï¼‰
```python
# Bad: æ¨è«–æ™‚ã«forward()å†…ã§æ¯å›ãƒªã‚»ãƒƒãƒˆ
def forward(self, ...):
    self.memory.reset(...)  # âŒ é•·æ–‡ã§éå»æƒ…å ±ãŒæ¶ˆãˆã‚‹

# Good: æ¡ä»¶ä»˜ããƒªã‚»ãƒƒãƒˆ
def forward(self, ...):
    if self.training or memory_not_initialized:
        self.memory.reset(...)  # âœ… å­¦ç¿’æ™‚ã®ã¿æ¯å›ãƒªã‚»ãƒƒãƒˆ
```

**ç—‡çŠ¶**: NIAHè©•ä¾¡ã§æ­£ç­”ç‡0%ã€é•·æ–‡ç”Ÿæˆã§å‰åŠã®æƒ…å ±ã‚’å‚ç…§ã§ããªã„

### 5. retrieveâ†’updateé †åºå•é¡Œï¼ˆè‡´å‘½çš„ï¼‰
```python
# Bad: retrieveâ†’updateé †åºï¼ˆå­¦ç¿’æ™‚ã«ãƒ¡ãƒ¢ãƒªãŒå¸¸ã«ã‚¼ãƒ­ï¼‰
def forward(self, ...):
    self.memory.reset(...)           # å­¦ç¿’æ™‚ã¯æ¯å›ãƒªã‚»ãƒƒãƒˆ
    global_out = self.memory.retrieve(q)  # âŒ MãŒã‚¼ãƒ­ãªã®ã§å‡ºåŠ›ã‚‚ã‚¼ãƒ­
    self.memory.update(k, v)         # Mã«å€¤ã‚’è¿½åŠ ï¼ˆæ¬¡ã§æ¶ˆãˆã‚‹ï¼‰

# Good: updateâ†’retrieveé †åº
def forward(self, ...):
    self.memory.reset(...)           # å­¦ç¿’æ™‚ã¯æ¯å›ãƒªã‚»ãƒƒãƒˆ
    self.memory.update(k, v)         # âœ… ã¾ãšMã«å€¤ã‚’è¿½åŠ 
    global_out = self.memory.retrieve(q)  # Mã«å€¤ãŒã‚ã‚‹ã®ã§æ­£å¸¸å‹•ä½œ
```

**ç—‡çŠ¶**: å­¦ç¿’ä¸­ã«ãƒ¡ãƒ¢ãƒªã‹ã‚‰ã®å‡ºåŠ›ãŒå¸¸ã«ã‚¼ãƒ­ã€ãƒ¡ãƒ¢ãƒªã‚²ãƒ¼ãƒˆãŒå­¦ç¿’ã•ã‚Œãªã„

**æ³¨æ„**: ã“ã®é †åºå¤‰æ›´ã¯å³å¯†ãªå› æœæ€§ã‚’ç·©å’Œã™ã‚‹ãŒã€å˜ä¸€forward-passå­¦ç¿’ã§ã¯å¿…è¦ã€‚
è«–æ–‡æº–æ‹ ã®ãƒãƒ£ãƒ³ã‚¯å˜ä½å‡¦ç†ã‚’å®Ÿè£…ã™ã‚Œã°ã€retrieveâ†’updateé †åºã§ã‚‚å‹•ä½œã™ã‚‹ã€‚

### 6. ãƒ¡ãƒ¢ãƒªæ›´æ–°æ™‚ã®éåº¦ãªdetachï¼ˆè‡´å‘½çš„ï¼‰
```python
# Bad: keys/valuesã‚’detachã—ã¦ãƒ¡ãƒ¢ãƒªæ›´æ–°
def update(self, keys, values):
    keys_detached = keys.detach()      # âŒ å‹¾é…çµŒè·¯ãŒå®Œå…¨ã«åˆ‡æ–­
    values_detached = values.detach()  # âŒ ãƒ¡ãƒ¢ãƒªã‹ã‚‰å­¦ç¿’ã§ããªã„
    delta_M = einsum(values_detached, keys_detached)
    self.M = self.M + delta_M

# Good: ç´¯ç©çŠ¶æ…‹ã®ã¿detachã€ç¾åœ¨ã®æ›´æ–°ã¯å‹¾é…ã‚’ç¶­æŒ
def update(self, keys, values):
    delta_M = einsum(values, keys)     # âœ… ç¾åœ¨ã®å…¥åŠ›ã‹ã‚‰ã®å‹¾é…ã‚’ç¶­æŒ
    self.M = self.M.detach() + delta_M # âœ… éå»ã®ç´¯ç©ã®ã¿detach
```

**ç—‡çŠ¶**: eval_loss ãŒ NaNã€å­¦ç¿’ãŒå…¨ãé€²ã¾ãªã„ã€ãƒ¡ãƒ¢ãƒªã‚²ãƒ¼ãƒˆã®å­¦ç¿’ã®ã¿ç™ºç”Ÿ

**åŸç†**:
- å­¦ç¿’æ™‚ã€å„ã‚µãƒ³ãƒ—ãƒ«ã¯ç‹¬ç«‹ï¼ˆæ¯å›ãƒ¡ãƒ¢ãƒªãƒªã‚»ãƒƒãƒˆï¼‰
- ç¾åœ¨ã‚µãƒ³ãƒ—ãƒ«å†…ã® update â†’ retrieve å‹¾é…çµŒè·¯ã¯å¿…è¦
- è¤‡æ•°ã‚µãƒ³ãƒ—ãƒ«é–“ã§ã®å‹¾é…ç´¯ç©ã¯ä¸è¦ï¼ˆdetachã§é˜²ãï¼‰
- `self.M.detach() + delta_M` ã§ã€Œéå»ã‚’ã‚«ãƒƒãƒˆã€ç¾åœ¨ã¯ç¶­æŒã€ã‚’å®Ÿç¾

## Debugging Tips

### ãƒ¡ãƒ¢ãƒªçŠ¶æ…‹ã®ç¢ºèª
```python
print(f"Memory M norm: {memory.M.norm()}")
print(f"Memory z norm: {memory.z.norm()}")
```

### Attentioné‡ã¿ã®å¯è¦–åŒ–
```python
import matplotlib.pyplot as plt
plt.imshow(attention_weights[0, 0].detach().cpu())
```

## Experiment Environment

### ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒ
- **ç”¨é€”**: ç°¡å˜ãªå‹•ä½œç¢ºèªã®ã¿
- **ãƒ†ã‚¹ãƒˆ**: `pytest tests/`
- **å‹•ä½œç¢ºèª**: `python scripts/local_test.py`

### Google Colabï¼ˆæœ¬å®Ÿé¨“ç’°å¢ƒï¼‰
- **ç”¨é€”**: æœ¬æ ¼çš„ãªå­¦ç¿’ãƒ»è©•ä¾¡å®Ÿé¨“
- **GPU**: T4 / A100 ã‚’æƒ³å®š
- **ã‚¹ã‚¯ãƒªãƒ—ãƒˆ**: `scripts/colab.py`

### Colabã§ã®å®Ÿè¡Œæ‰‹é †

```python
# 1. ãƒªãƒã‚¸ãƒˆãƒªã®ã‚¯ãƒ­ãƒ¼ãƒ³
!git clone https://github.com/YOUR_USERNAME/senri-llm.git
%cd senri-llm

# 2. ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
!pip install -e .

# 3. è¨­å®šã®ç¢ºèªãƒ»ç·¨é›†ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
# config/training.yaml ã‚’ç·¨é›†ã—ã¦å­¦ç¿’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’èª¿æ•´

# 4. å®Ÿé¨“ã®å®Ÿè¡Œ
!python scripts/colab.py train   # å­¦ç¿’
!python scripts/colab.py test    # å‹•ä½œç¢ºèª
!python scripts/colab.py eval    # è©•ä¾¡
```

### Colab Notebookæ§‹æˆ

```
notebooks/
â”œâ”€â”€ 01_model_test.ipynb      # ãƒ¢ãƒ‡ãƒ«å‹•ä½œç¢ºèª
â”œâ”€â”€ 02_training.ipynb        # å­¦ç¿’å®Ÿé¨“
â”œâ”€â”€ 03_evaluation.ipynb      # è©•ä¾¡å®Ÿé¨“ï¼ˆRULER, NIAHç­‰ï¼‰
â””â”€â”€ 04_analysis.ipynb        # çµæœåˆ†æãƒ»å¯è¦–åŒ–
```

### GPU ãƒ¡ãƒ¢ãƒªç®¡ç†ï¼ˆColabï¼‰

```python
# ãƒ¡ãƒ¢ãƒªã‚¯ãƒªã‚¢
import gc
import torch
gc.collect()
torch.cuda.empty_cache()

# ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ç¢ºèª
print(f"GPU Memory: {torch.cuda.memory_allocated() / 1e9:.2f} GB")
```

### Checkpointingï¼ˆColabï¼‰

```python
# Google Driveã¸ã®ä¿å­˜
from google.colab import drive
drive.mount('/content/drive')

# ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜
model.save_pretrained('/content/drive/MyDrive/senri-checkpoints/epoch_1')
```
